Welcome
=====

This is the source code for MpdFS described in our paper. 
The system is tested on Ubuntu 12.04.2 64-bit with GCC 4.6.3. 

Installation
=====

These are the required libraries that users need to download separately. 
Brackets denote the package names in Debian and Ubuntu platforms. 
Users can use apt-get to install the required libraries. 

 - build-essential (build-essential)
 - scons (scons)
 - boost libraries version 1.5x (libboost-dev, libboost-program-options-dev, libboost-thread-dev, libboost-filesystem-dev)
 - FUSE (libfuse-dev)
 - openssl (libssl-dev)
 - pkg-config (pkg-config)

For Debian and Ubuntu users:

```
sudo apt-get install build-essential scons libboost-dev libboost-program-options-dev libboost-thread-dev libboost-filesystem-dev libfuse-dev libssl-dev pkg-config
```

The following libraries have to be compiled and installed manually:

**Google Protocol Buffers**

```
$ cd lib/protobuf-2.4.1
$ ./configure; make clean; make
$ sudo make install
$ sudo ln -s /usr/local/lib/libprotobuf.so.7 /usr/lib/libprotobuf.so.7
$ sudo ln -s /usr/local/lib/libprotoc.so.7 /usr/lib/libprotoc.so.7
```

**MongoDB C++ Driver (only required for MASTER)**

```
$ cd lib/mongo
$ sudo scons install
```

Preparation
=====

Compile
-----------

The program can be compiled using Linux make. 
Running make on the MpdFS root will automatically compile all MpdFS components.

```
$ make
```

For optimal performance, turn off debug mode by editing the following flags in Makefile:

```
OPTIMIZE := -O3
EXTRA_CFLAGS := -std=c++0x -DDEBUG=0 -D_FILE_OFFSET_BITS=64
```

Setting up MongoDB
-----------

We suggest hosting the MongoDB on the MASTER for optimal performance.

 - Set up MongoDB environment

   On the MongoDB host, create the database parent directory

   ```
   $ sudo mkdir -p /data/db
   ```

   Change the MongoDB address "[mongodb_ip]:[mongodb_port]" in "mongo-mpdfs.js" if necessary

   ```    
   db = connect("localhost:27017/mpdfs");
   ```

   Change the default MongoDB password in "mongo-mpdfs.js" for security reasons

   ```
   "pwd": "cf8b7fa0b1bcd277da8217f04f498bd0"
   ```

   **Note**

   - "pwd" should be an MD5 hash, which can be generated by running `echo 'NEWPASSWORD' | md5sum` in Linux

 - Change to the directory containing the MongoDB binary

   ```
   $ cd mongo/bin
   ```

 - Start MongoDB daemon

   ```
   $ sudo ./mongod --fork --dbpath /data/db --logpath /var/log/mongodb.log --logappend
   ```

 - Import MongoDB Setting

   ```
   $ ./mongo ../../mongo-mpdfs.js
   ```

Adjusting XML Settings
------------------

- Copy one of the two set of example XML files from the directory to the MpdFS root (same level as the executables)
  For standalone setup, `cp example_xml/standalone/* .`
  For distributed setup, `cp example_xml/distributed/* .`

 - example_xml/standalone/
   - Example XML files for a standalone setup which runs all components on localhost (127.0.0.1)

 - example_xml/distributed/
   - Example XML files for a distributed setup
     - MONITOR on 192.168.0.11:53000
     - MASTER on 192.168.0.12:50000
     - MongoDB daemon on 192.168.0.12:27017    

- Adjust the following essential parameters in the XML files according to the cluster setup:

 - `masterconfig.xml`
   - MASTER listen port
   - MongoDB IP address, listen port, password
 - `chunkserverconfig.xml`
   - Update scheme (FO=0, FL=1, PL=2, PLR=3, MPLR=4) and reserved space size
 - `monitorconfig.xml`
   - MONITOR listen port
 - `clientconfig.xml`
   - Coding scheme (e.g., RS, RDP) and coding settings (e.g. n, k)
 - `common.xml`
   - MASTER IP address and listen port
   - MONITOR IP address and listen port

- Refer to comments in the XML files for other individual settings (e.g., Chunkserver capacity)

Running MpdFS
=====

Server-side
----------------------

Copy the corresponding executable (MONITOR, MASTER or Chunkserver) and all the XML files to each server

Start the components in the following order

 - MONITOR

   ```
   $ ./MONITOR
   ```

 - MASTER 

   ```
   $ ./MASTER
   ```

 - Start Chunkserver one-by-one

   ```
   $ ./CHUNKSERVER [component_id] [network_interface] 
   ```

**Note**


 - Assign a `component_id` that is unique from MASTER, MONITOR, other Chunkservers and clients
 - Use "ifconfig" to check the name of the network interface (e.g., eth0). If multiple interfaces exist, select the one that can be reached by other components 


Client-side
---------------------------

On the client machine, create two directories

```
$ mkdir fusedir mountdir
```

Mount the FUSE volume with the following options

```
$ ./CLIENT_FUSE -o big_writes,large_read,noatime -f mountdir [component_id]
```

You can now access MpdFS through `mountdir`. The following command copies a file into the cluster and outputs the time spent:

```
$ time cp testfile mountdir/
```

**Note**

 - Assign a `component_id` that is unique from MASTER, MONITOR, Chunkservers and other clients

Benchmarks
=================

Test seq. read/write throughput using dd
-------------------------------------

After mounting the FUSE volume, test seq. write throughput by:

```
$ dd if=/dev/zero of=mountdir/ddtest count=256 bs=16M conv=fdatasync
```


After random writes(using IOzone), test seq. read throughput by:

```
$ dd if=mountdir/ddtest of=/dev/null count=256 bs=16M
```

Test random write throughput using IOzone
---------------------------------------------

Download latest IOzone tarball from http://www.iozone.org/.

Compile IOzone from source

```
$ tar xf iozone3_424.tar
$ cd iozone3_424/src/current
$ make linux-AMD64
```

Copy the IOzone executable to Mpdroot, and execute the following:

```
$ ./iozone -Ra -+n -i0 -i2 -s 4g -r 128k -e -c -w -f mountdir/iozonetest
```

This will create a 4GB file and perform random read/write with 128KB record size.

Recovery
=================

Automatic Recovery
-------------------------------------

MpdFS does not automatically recover by default.
To enable this features, uncomment the line `#define TRIGGER_RECOVERY` in `src/common/define.hh`

**Note**

 - Adjust the sensitivity of recovery trigger by changing `SleepPeriod`, `DeadPeriod` and `UpdatePeriod` in `monitorconfig.xml`

Manual Recovery
-------------------------------------

Manual recovery is useful in benchmarks.

To simulate failure, kill the Chunkserver process on one of the Chunkserver hosts

```
$ pkill -9 CHUNKSERVER
```

To force failure detection and recovery, send a signal to the MONITOR process on the MONITOR host

```
$ pkill -USR1 MONITOR
```

Traces
=================

NFS Traces
-------------------------------------

MpdFS use Harvard NFS traces to evaluate（Harvard SOS Traces：http://iotta.snia.org/traces/nfs/3378）

Classifier
-------------------------------------

MpdFS-Classifier is built in the environment of python3

How to use：

1. run readTraces，read core records from old traces（from NFS traces）
2. run createUser and createScheme， create certain features needed for training
3. run createFiles，generate all required feature sets from the processed dataset and created rule set
4. run createTrainSets，generate dataset and training set
5. run mainTest，evaluate prediction performance
6. run readOnlyMain，predict read-only or not

**Note**

 - Some file path parameters in the code need to be entered manually, for example “old_txt_path”，“csv_path”...

Contact
=================

Xiaosong Su (Email: sxsbilly@163.com)

